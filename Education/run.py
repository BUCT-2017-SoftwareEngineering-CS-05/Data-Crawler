import scrapy
from scrapy.crawler import CrawlerProcess
import tutorial.spiders
from scrapy import cmdline
# cmdline.execute('scrapy crawl dmpEducation'.split())
# cmdline.execute('scrapy crawl gmcEducation'.split())
# cmdline.execute('scrapy crawl cstmEducation'.split())
# cmdline.execute('scrapy crawl jbEducation'.split())
# cmdline.execute('scrapy crawl luxEducation'.split())
# cmdline.execute('scrapy crawl capEducation'.split())
# cmdline.execute('scrapy crawl bmnhEducation'.split())
# cmdline.execute('scrapy crawl 1937Education'.split())
# cmdline.execute('scrapy crawl zkdEducation'.split())
# cmdline.execute('scrapy crawl ciaeEducation'.split())
# cmdline.execute('scrapy crawl pgmEducation'.split())
# cmdline.execute('scrapy crawl tjEducation'.split())
cmdline.execute('scrapy crawl 126'.split())

# cmdline.execute('scrapy crawlall'.split())

